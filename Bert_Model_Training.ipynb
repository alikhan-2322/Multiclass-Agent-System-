{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:01:06.429010Z",
     "iopub.status.busy": "2025-05-10T15:01:06.428749Z",
     "iopub.status.idle": "2025-05-10T21:37:50.689726Z",
     "shell.execute_reply": "2025-05-10T21:37:50.688876Z",
     "shell.execute_reply.started": "2025-05-10T15:01:06.428990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 15:01:19.306237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746889279.482817      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746889279.536382      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dataset loaded with shape: (11200, 14)\n",
      "Columns: ['merge_key', 'PrimaryCategory', 'Title', 'Description', 'APIProvider', 'APIEndpoint', 'SupportedResponseFormats', 'SupportedRequestFormats', 'AuthenticationModel', 'ArchitecturalStyle', 'RestrictedAccess', 'SSLSupport', 'IsThisanUnofficialAPI', 'SecondaryCategories']\n",
      "Number of unique labels: 509\n",
      "Labels: ['3D' '3D|Authentication' 'API' 'API Design'\n",
      " 'API Design|Cameras|Cloud|Games|Health|Home Automation|Photos|Security'\n",
      " 'API Education' 'API Management'\n",
      " 'API Management|Browsers|Contacts|Database|Internet of Things|Management|Messaging|Networking|Notifications|Statistics|Tasks|Telephony|Time|Tools|Visualizations|Wi-Fi'\n",
      " 'API|Credit Cards' 'Accessibility' 'Accounting' 'Accounts'\n",
      " 'Accounts|Activity Streams|Metadata|Social'\n",
      " 'Accounts|Analytics|Banking|Billing|Demographics|Financial|Payments|Rewards|Sales'\n",
      " 'Accounts|Analytics|Real Time|eCommerce'\n",
      " 'Accounts|Campaigns|Contacts|Content|Data|Marketing|Reporting|SEO'\n",
      " 'Activity Streams' 'Addresses'\n",
      " 'Addresses|Billing|Booking|Catalogs|Customer Relationship Management|Events|Ordering|Performance|Products|Tools'\n",
      " 'Addresses|Email|Telephony' 'Addresses|Financial' 'Adoption' 'Adult'\n",
      " 'Advertising'\n",
      " 'Advertising|Agents|Analytics|Application Development|Applications|Auctions|Audio|Authentication|Auto|Automation|Backend|Barcodes|Blogging|Bookmarks|Bots|Browsers|Business|Calendars|Captcha|Catalogs|Charts|Chat|Classification|Cloud|Collaboration|Contacts|Content Management|Customization|Dashboards|Data|Database|Dating|Design|Dictionary|Digital Asset Management|Domains|Drugs|Education|Email|Energy|Engagement|Enterprise|Entertainment|European|Events|Fax|Feedback|Feeds|File Sharing|Financial|Food|French|Games|Goals|Government|Home Automation|Hosting|Images|Internet of Things|Jobs|Management|Manufacturing|Mapping|Marketing|Media|Medical|Messaging|Mobile|Monitoring|Music|Natural Language Processing|Networking|News Services|Notifications|OCR|Office|Open Source|Other|Payments|Personal Information Management|Photos|Platform-as-a-Service|Predictions|Project Management|Q&A|Real Estate|Real Time|Recommendations|Reference|Referrals|Reporting|SEO|SQL|Science|Search|Security|Sentiment|Shipping|Social|Spam|Spelling|Sports|Statistics|Storage|Surveys|Syncing|Telephony|Text|Tools|Translation|Transportation|Travel|URL Shortener|URLs|Validation|Video|Voice|Weather|Web Site Management|Webhooks|Widgets|Wiki|eCommerce'\n",
      " 'Advertising|Feeds' 'African' 'Agents' 'Aggregation' 'Agile'\n",
      " 'Agriculture' 'Agriculture|Weather' 'Air Travel' 'Air Travel|Travel'\n",
      " 'Algorithms' 'Analytics'\n",
      " 'Analytics|Application Development|Catalogs|Cloud|Email|Games|Images|Messaging|NoSQL|Notifications|Social|Storage|eCommerce'\n",
      " 'Analytics|Applications|Catalogs|Customer Relationship Management|Customer Service|Networking|Ordering|Payments|Software-as-a-Service'\n",
      " 'Analytics|Data' 'Analytics|Language|Q&A|Text|Translation|Words'\n",
      " 'Analytics|Location|Mapping' 'Analytics|Profiles' 'Analytics|Publishing'\n",
      " 'Animals' 'Animation' 'Annotations' 'Annotations|Recognition'\n",
      " 'Announcements|Classifieds' 'Application Development'\n",
      " 'Application Development|Applications|Backup|File Sharing|Images|Infrastructure-as-a-Service|Networking|Search|Security|Software-as-a-Service'\n",
      " 'Application Development|Artificial Intelligence|Cloud|Content|Developers|Hosting|Lists|eCommerce'\n",
      " 'Application Development|Audio|Authentication|Auto|Budget|Content|Database|Directories|Documents|Geography|Images|Location|Media|Notifications|Parsing|Payments|Performance|Privacy|Publishing|Scheduling|Security|Semantic Web|Storage|Time|Tools|Visualizations|WebRTC'\n",
      " 'Application Development|Cloud'\n",
      " 'Application Development|Data|Financial|Profiles|Reporting'\n",
      " 'Application Development|eCommerce' 'Applications'\n",
      " 'Applications|Database-as-a-Service' 'Art' 'Artificial Intelligence'\n",
      " 'Astrology' 'Astronomy' 'Astronomy|Images' 'Auctions'\n",
      " 'Auctions|Marketplace' 'Audio' 'Audio|Browsers|Data' 'Audio|Data'\n",
      " 'Audio|Text-to-Speech' 'Augmented Reality'\n",
      " 'Augmented Reality|Browsers|Data|DevOps|Games|Images|Natural Language Processing|Payments|Recognition|Storage|URLs'\n",
      " 'Augmented Reality|Data|Social' 'Australian' 'Authentication'\n",
      " 'Authentication|Predictions' 'Authorization' 'Auto' 'Automation'\n",
      " 'Auto|Data' 'Availability' 'Avatars'\n",
      " 'Avatars|Recognition|Text-to-Speech|Video' 'B2B' 'Backend'\n",
      " 'Backend-as-a-Service' 'Backend|Cloud|Office|Reporting' 'Backend|Other'\n",
      " 'Background' 'Backup' 'Badges' 'Banking' 'Banking|Financial'\n",
      " 'Banking|Financial|Stocks' 'Banking|Payments' 'Barcodes'\n",
      " 'Barcodes|Cloud|Documents|OCR|PDF' 'Beer' 'Big Data' 'Billing' 'Bitcoin'\n",
      " 'Bitcoin|Financial' 'Blockchain' 'Blogging' 'Bluetooth' 'Booking'\n",
      " 'Bookmarks' 'Books' 'Bots' 'Bots|Internet of Things|Payments|Search'\n",
      " 'Bots|Messaging' 'Browsers' 'Browsers|Campaigns|Marketplace'\n",
      " 'Browsers|Data' 'Budget' 'Business'\n",
      " 'Business|Calendars|Contacts|Customer Relationship Management|Monitoring|Social|Webhooks|eCommerce'\n",
      " 'Business|Cloud|Data' 'Business|Customer Relationship Management'\n",
      " 'Business|Enterprise' 'Caching' 'Calendars' 'Calendars|Office' 'Cameras'\n",
      " 'Cameras|Cloud|Reporting' 'Campaigns' 'Campaigns|Measurements|Profiles'\n",
      " 'Canadian' 'Captcha' 'Catalogs' 'Charity' 'Charts' 'Chat'\n",
      " 'Chat|Contacts|Images|News Services|Photos|Q&A|Recognition|Semantics|Storage|Text-to-Speech|Weather'\n",
      " 'Chat|Data|Monitoring' 'Chinese' 'Cities' 'Civics' 'Classification'\n",
      " 'Classifieds' 'Climate' 'Clothing' 'Cloud' 'Cloud|Internet of Things'\n",
      " 'Cloud|Video' 'Collaboration' 'Colors' 'Community' 'Comparisons'\n",
      " 'Compliance' 'Contacts' 'Contacts|Messaging' 'Content'\n",
      " 'Content Management' 'Content|Content Management'\n",
      " 'Content|Customization|Metadata|Social' 'Content|Financial' 'Contracts'\n",
      " 'Conversions' 'Copyright' 'Countries' 'Coupons' 'Credit Cards' 'Crime'\n",
      " 'Crowdsourcing' 'Cryptocurrency' 'Currency'\n",
      " 'Currency|Language|Software-as-a-Service|Validation'\n",
      " 'Customer Relationship Management'\n",
      " 'Customer Relationship Management|Customization' 'Customer Service'\n",
      " 'Customization' 'Cycling' 'Dashboards' 'Data' 'Data Mining'\n",
      " 'Data-as-a-Service' 'Database' 'Database-as-a-Service'\n",
      " 'Database-as-a-Service|Plugins' 'Datacenter' 'Data|File Sharing'\n",
      " 'Data|File Sharing|Metadata' 'Data|Mapping' 'Demographics' 'Design'\n",
      " 'Design|Models' 'DevOps' 'Developer Relations' 'Developers' 'Dictionary'\n",
      " 'Digital Asset Management' 'Directories' 'Discounts' 'Documents'\n",
      " 'Documents|Email' 'Domains' 'Drawing' 'Drugs' 'ERP' 'Economics|Stocks'\n",
      " 'Editing' 'Education' 'Electronic Signature' 'Email' 'Email|Images|Tasks'\n",
      " 'Email|Statistics' 'Emergency' 'Encoding' 'Energy' 'Engagement'\n",
      " 'Enterprise' 'Enterprise|Government' 'Enterprise|Internet of Things'\n",
      " 'Entertainment' 'Entertainment|Video' 'Environment' 'Events' 'Extraction'\n",
      " 'Fantasy Sports' 'Fashion' 'Fax' 'Feedback' 'Feeds' 'Feeds|Search'\n",
      " 'File Sharing' 'Financial' 'Financial|Stocks' 'Fitness'\n",
      " 'Fitness|Mapping|Video' 'Flowers' 'Fonts' 'Food' 'Forms' 'Forums'\n",
      " 'Framework' 'French' 'Funding' 'Gadgets' 'Gambling' 'Games' 'Genetics'\n",
      " 'Geography' 'German' 'Gestures' 'Gifts' 'Goals' 'Government' 'Graphics'\n",
      " 'Grocery' 'HTML5' 'Hacking' 'Hardware' 'Health' 'Healthcare' 'History'\n",
      " 'Holidays' 'Home Automation' 'Hosting' 'Hotels' 'Housing'\n",
      " 'Human Resources' 'Humor' 'IDE' 'Identity' 'Images' 'Images|Search'\n",
      " 'Images|Text' 'Indian' 'Infrastructure-as-a-Service' 'Insurance'\n",
      " 'Integration' 'Intelligence' 'International' 'Internet of Things'\n",
      " 'Inventory' 'Invoicing' 'Japanese' 'Jobs' 'Jobs|Printing' 'Keywords'\n",
      " 'Language' 'Languages' 'Law' 'Learning Management Systems' 'Library'\n",
      " 'Library|Metadata' 'Licensing' 'Linked Data' 'Lists' 'Localization'\n",
      " 'Location' 'Location|Mapping' 'Logistics' 'Loyalty' 'Lyrics'\n",
      " 'Machine Learning' 'Machine Learning|Natural Language Processing'\n",
      " 'Machine-to-Machine' 'Mail' 'Management' 'Manufacturing' 'Mapping'\n",
      " 'Mapping|Messaging' 'Mapping|Music' 'Marine' 'Marketing' 'Marketplace'\n",
      " 'Mashups' 'Math' 'Measurements' 'Media' 'Medical' 'Medical Records'\n",
      " 'Medicine' 'Meetings' 'Meme' 'Merchants' 'Messaging'\n",
      " 'Messaging|Platform-as-a-Service'\n",
      " 'Messaging|Prices|Teleconferencing|Telephony|Text-to-Speech|Voice'\n",
      " 'Messaging|Reporting|Telephony|Verification|Voice' 'Messaging|Search'\n",
      " 'Messaging|Telephony' 'Metadata' 'Microservices' 'Mobile' 'Models'\n",
      " 'Modules' 'Monetization' 'Monitoring' 'Motion' 'Movies' 'Museums' 'Music'\n",
      " 'Names' 'Natural Language Processing' 'Networking' 'News Services'\n",
      " 'News Services|Social' 'News Services|Stocks|Weather' 'Newsletters'\n",
      " 'NoSQL' 'Non-Profit' 'Notes' 'Notifications' 'Nutrition' 'OAuth' 'OCR'\n",
      " 'Office' 'Open Data' 'Open Graph' 'Open Source' 'Optimization' 'Ordering'\n",
      " 'Organization' 'Other' 'PDF' 'Panorama' 'Parking' 'Parsing' 'Passwords'\n",
      " 'Pastebin' 'Patents' 'Payments' 'Payments|Recognition|TV'\n",
      " 'Payments|eCommerce' 'Performance' 'Personal Information Management'\n",
      " 'Pets' 'Photos' 'Planning' 'Platform-as-a-Service'\n",
      " 'Platform-as-a-Service|Telephony' 'Plugins' 'Podcasts' 'Politics' 'Polls'\n",
      " 'Postal' 'Postcodes' 'Predictions' 'Presentations' 'Prices' 'Printing'\n",
      " 'Privacy' 'Products' 'Profiles' 'Project Management'\n",
      " 'Project Management|Software-as-a-Service' 'Project Management|Tools'\n",
      " 'Publishing' 'Purchasing' 'Q&A' 'QR Codes' 'RDF' 'REST' 'Random'\n",
      " 'Ratings' 'Real Estate' 'Real Time' 'Recognition' 'Recognition|Search'\n",
      " 'Recommendations' 'Recreation' 'Reference' 'Reference|Telephony'\n",
      " 'Referrals' 'Registration' 'Registry' 'Religion' 'Rentals' 'Reporting'\n",
      " 'Reputation' 'Reservations' 'Restaurants' 'Rewards' 'Robots' 'Russian'\n",
      " 'SEO' 'SQL' 'Safety' 'Sales' 'Satellites' 'Scheduling' 'Science'\n",
      " 'Science|Weather' 'Screenshots' 'Search' 'Search|Web Site Management'\n",
      " 'Security' 'Semantic Web' 'Semantics' 'Semantics|Sentiment' 'Sentiment'\n",
      " 'Shipping' 'Social' 'Software-as-a-Service'\n",
      " 'Software-as-a-Service|eCommerce' 'Solar' 'Spam' 'Spelling' 'Sports'\n",
      " 'Spreadsheets' 'Standards' 'Statistics' 'Stocks' 'Storage' 'Streaming'\n",
      " 'Subscriptions' 'Subtitles' 'Summary' 'Supply Chain' 'Support' 'Surveys'\n",
      " 'Sustainability' 'Syncing' 'TV' 'Tagging' 'Tasks' 'Taxes'\n",
      " 'Teleconferencing' 'Telephony' 'Testing' 'Text' 'Text-to-Speech'\n",
      " 'Text|Tools' 'Tickets' 'Time' 'Time Tracking' 'Tools' 'Torrents'\n",
      " 'Tourism' 'Training' 'Transactions' 'Transcription' 'Translation'\n",
      " 'Transportation' 'Travel' 'Trivia' 'Tweets' 'URL Shortener' 'URLs'\n",
      " 'Upload' 'Validation' 'Verification' 'Video' 'Viewer' 'Virtualization'\n",
      " 'Visualizations' 'VoIP' 'Voice' 'Voting' 'Water' 'Wearable' 'Weather'\n",
      " 'Web Site Management' 'WebRTC' 'Webhooks' 'Wi-Fi' 'Widgets' 'Wiki' 'Wine'\n",
      " 'Wireless' 'Words' 'Writing' 'Zip Codes' 'eBooks' 'eCommerce' 'eSports'\n",
      " 'iPaaS' nan]\n",
      "Training set size: 8960\n",
      "Validation set size: 2240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00af14c9218e437b875e4436a2458aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b71de92b2424e02bdecec07fbe85487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79526a53ecf492cb2ed71f70df4b2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f44b492d4340a88335f0cf274db18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91717ec404d14dd69ac26df9394d5b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:05<00:00,  1.51s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 4.8093\n",
      "Training metrics: Accuracy=0.1890, F1=0.1372, Precision=0.1872, Recall=0.1890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.9253\n",
      "Validation metrics: Accuracy=0.3384, F1=0.2327, Precision=0.2574, Recall=0.3384\n",
      "New best F1 score: 0.2327. Saving model...\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:30<00:00,  1.56s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 3.4884\n",
      "Training metrics: Accuracy=0.4061, F1=0.3069, Precision=0.2829, Recall=0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:17<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2827\n",
      "Validation metrics: Accuracy=0.4259, F1=0.3281, Precision=0.3012, Recall=0.4259\n",
      "New best F1 score: 0.3281. Saving model...\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:30<00:00,  1.56s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.8490\n",
      "Training metrics: Accuracy=0.4940, F1=0.3906, Precision=0.3632, Recall=0.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.9312\n",
      "Validation metrics: Accuracy=0.4732, F1=0.3784, Precision=0.3287, Recall=0.4732\n",
      "New best F1 score: 0.3784. Saving model...\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:31<00:00,  1.56s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.3934\n",
      "Training metrics: Accuracy=0.5595, F1=0.4612, Precision=0.4320, Recall=0.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:17<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.7414\n",
      "Validation metrics: Accuracy=0.4902, F1=0.4097, Precision=0.3749, Recall=0.4902\n",
      "New best F1 score: 0.4097. Saving model...\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:30<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 2.0269\n",
      "Training metrics: Accuracy=0.6183, F1=0.5311, Precision=0.5077, Recall=0.6183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6236\n",
      "Validation metrics: Accuracy=0.5080, F1=0.4415, Precision=0.4206, Recall=0.5080\n",
      "New best F1 score: 0.4415. Saving model...\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:29<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.7106\n",
      "Training metrics: Accuracy=0.6748, F1=0.5997, Precision=0.5825, Recall=0.6748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5596\n",
      "Validation metrics: Accuracy=0.5210, F1=0.4636, Precision=0.4423, Recall=0.5210\n",
      "New best F1 score: 0.4636. Saving model...\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:29<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.4303\n",
      "Training metrics: Accuracy=0.7273, F1=0.6624, Precision=0.6267, Recall=0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5303\n",
      "Validation metrics: Accuracy=0.5330, F1=0.4872, Precision=0.4734, Recall=0.5330\n",
      "New best F1 score: 0.4872. Saving model...\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.2005\n",
      "Training metrics: Accuracy=0.7754, F1=0.7206, Precision=0.7015, Recall=0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5107\n",
      "Validation metrics: Accuracy=0.5299, F1=0.4893, Precision=0.4713, Recall=0.5299\n",
      "New best F1 score: 0.4893. Saving model...\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.0099\n",
      "Training metrics: Accuracy=0.8122, F1=0.7657, Precision=0.7489, Recall=0.8122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5288\n",
      "Validation metrics: Accuracy=0.5353, F1=0.5026, Precision=0.4966, Recall=0.5353\n",
      "New best F1 score: 0.5026. Saving model...\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.8479\n",
      "Training metrics: Accuracy=0.8489, F1=0.8096, Precision=0.7966, Recall=0.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4858\n",
      "Validation metrics: Accuracy=0.5335, F1=0.5045, Precision=0.4932, Recall=0.5335\n",
      "New best F1 score: 0.5045. Saving model...\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:29<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7216\n",
      "Training metrics: Accuracy=0.8748, F1=0.8430, Precision=0.8328, Recall=0.8748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5384\n",
      "Validation metrics: Accuracy=0.5437, F1=0.5219, Precision=0.5247, Recall=0.5437\n",
      "New best F1 score: 0.5219. Saving model...\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:29<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.6056\n",
      "Training metrics: Accuracy=0.8993, F1=0.8729, Precision=0.8617, Recall=0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5342\n",
      "Validation metrics: Accuracy=0.5442, F1=0.5241, Precision=0.5268, Recall=0.5442\n",
      "New best F1 score: 0.5241. Saving model...\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5092\n",
      "Training metrics: Accuracy=0.9172, F1=0.8951, Precision=0.8852, Recall=0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5356\n",
      "Validation metrics: Accuracy=0.5420, F1=0.5196, Precision=0.5204, Recall=0.5420\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.4355\n",
      "Training metrics: Accuracy=0.9340, F1=0.9159, Precision=0.9070, Recall=0.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6069\n",
      "Validation metrics: Accuracy=0.5442, F1=0.5225, Precision=0.5213, Recall=0.5442\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:26<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3829\n",
      "Training metrics: Accuracy=0.9420, F1=0.9261, Precision=0.9204, Recall=0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6303\n",
      "Validation metrics: Accuracy=0.5482, F1=0.5218, Precision=0.5191, Recall=0.5482\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3269\n",
      "Training metrics: Accuracy=0.9510, F1=0.9366, Precision=0.9285, Recall=0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6684\n",
      "Validation metrics: Accuracy=0.5487, F1=0.5324, Precision=0.5384, Recall=0.5487\n",
      "New best F1 score: 0.5324. Saving model...\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2791\n",
      "Training metrics: Accuracy=0.9614, F1=0.9498, Precision=0.9444, Recall=0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6566\n",
      "Validation metrics: Accuracy=0.5509, F1=0.5337, Precision=0.5337, Recall=0.5509\n",
      "New best F1 score: 0.5337. Saving model...\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2379\n",
      "Training metrics: Accuracy=0.9693, F1=0.9596, Precision=0.9545, Recall=0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.7091\n",
      "Validation metrics: Accuracy=0.5446, F1=0.5305, Precision=0.5360, Recall=0.5446\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:29<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2097\n",
      "Training metrics: Accuracy=0.9730, F1=0.9651, Precision=0.9614, Recall=0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.7817\n",
      "Validation metrics: Accuracy=0.5460, F1=0.5313, Precision=0.5397, Recall=0.5460\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1836\n",
      "Training metrics: Accuracy=0.9787, F1=0.9722, Precision=0.9686, Recall=0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8822\n",
      "Validation metrics: Accuracy=0.5397, F1=0.5257, Precision=0.5353, Recall=0.5397\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:26<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1943\n",
      "Training metrics: Accuracy=0.9730, F1=0.9663, Precision=0.9627, Recall=0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8390\n",
      "Validation metrics: Accuracy=0.5487, F1=0.5323, Precision=0.5359, Recall=0.5487\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:27<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1534\n",
      "Training metrics: Accuracy=0.9824, F1=0.9772, Precision=0.9741, Recall=0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.82it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8890\n",
      "Validation metrics: Accuracy=0.5437, F1=0.5326, Precision=0.5427, Recall=0.5437\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1620\n",
      "Training metrics: Accuracy=0.9808, F1=0.9766, Precision=0.9740, Recall=0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.9047\n",
      "Validation metrics: Accuracy=0.5379, F1=0.5249, Precision=0.5417, Recall=0.5379\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1251\n",
      "Training metrics: Accuracy=0.9864, F1=0.9830, Precision=0.9806, Recall=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8930\n",
      "Validation metrics: Accuracy=0.5478, F1=0.5305, Precision=0.5385, Recall=0.5478\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 560/560 [14:28<00:00,  1.55s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1040\n",
      "Training metrics: Accuracy=0.9906, F1=0.9878, Precision=0.9858, Recall=0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 140/140 [01:16<00:00,  1.83it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.9165\n",
      "Validation metrics: Accuracy=0.5464, F1=0.5339, Precision=0.5448, Recall=0.5464\n",
      "New best F1 score: 0.5339. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3614565084.py:104: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics plots saved as 'training_metrics.png' and 'combined_metrics.png'\n",
      "Training complete! Best validation F1 score: 0.5339\n",
      "Model and label encoder saved successfully!\n",
      "\n",
      "Prediction:\n",
      "Text: API that provides weather data with JSON responses\n",
      "Predicted category: Weather\n",
      "Top predictions with probabilities:\n",
      "  Weather: 0.9990\n",
      "  Data: 0.0001\n",
      "  Medical: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(csv_path):\n",
    "    \"\"\"Load and prepare the dataset from CSV file.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Print dataset info\n",
    "    print(f\"Dataset loaded with shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocess_data(df, text_columns=['Title', 'Description'], target_column='PrimaryCategory'):\n",
    "    \"\"\"Preprocess the data for BERT fine-tuning.\"\"\"\n",
    "    # Combine text columns\n",
    "    df['combined_text'] = df[text_columns].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df[target_column])\n",
    "\n",
    "    num_labels = len(label_encoder.classes_)\n",
    "    print(f\"Number of unique labels: {num_labels}\")\n",
    "    print(f\"Labels: {label_encoder.classes_}\")\n",
    "\n",
    "    return df, label_encoder, num_labels\n",
    "\n",
    "# Custom Dataset class\n",
    "class APIDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(preds, labels):\n",
    "    \"\"\"Calculate accuracy, F1, precision, and recall.\"\"\"\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix'):\n",
    "    \"\"\"Plot confusion matrix as a heatmap.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot metrics history\n",
    "def plot_metrics_history(metrics_history):\n",
    "    \"\"\"Plot the metrics over epochs.\"\"\"\n",
    "    epochs = range(1, len(metrics_history['train_loss'])+1)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Loss subplot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, metrics_history['train_loss'], 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, metrics_history['val_loss'], 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy subplot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, metrics_history['train_accuracy'], 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, metrics_history['val_accuracy'], 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # F1 Score subplot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, metrics_history['train_f1'], 'b-', label='Training F1')\n",
    "    plt.plot(epochs, metrics_history['val_f1'], 'r-', label='Validation F1')\n",
    "    plt.title('Training and Validation F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "\n",
    "    # Precision and Recall subplot\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs, metrics_history['train_precision'], 'b-', label='Training Precision')\n",
    "    plt.plot(epochs, metrics_history['train_recall'], 'b--', label='Training Recall')\n",
    "    plt.plot(epochs, metrics_history['val_precision'], 'r-', label='Validation Precision')\n",
    "    plt.plot(epochs, metrics_history['val_recall'], 'r--', label='Validation Recall')\n",
    "    plt.title('Training and Validation Precision/Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Generate the new combined metrics plot\n",
    "    plot_combined_metrics(metrics_history)\n",
    "\n",
    "    print(\"Metrics plots saved as 'training_metrics.png' and 'combined_metrics.png'\")\n",
    "\n",
    "# New function to plot all validation metrics together in one figure\n",
    "def plot_combined_metrics(metrics_history):\n",
    "    \"\"\"Plot all validation metrics together in one figure.\"\"\"\n",
    "    epochs = range(1, len(metrics_history['val_accuracy'])+1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot all validation metrics on the same graph\n",
    "    plt.plot(epochs, metrics_history['val_accuracy'], 'b-', linewidth=2, label='Accuracy')\n",
    "    plt.plot(epochs, metrics_history['val_f1'], 'r-', linewidth=2, label='F1 Score')\n",
    "    plt.plot(epochs, metrics_history['val_precision'], 'g-', linewidth=2, label='Precision')\n",
    "    plt.plot(epochs, metrics_history['val_recall'], 'y-', linewidth=2, label='Recall')\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title('Combined Validation Metrics Over Epochs', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Display epoch numbers on x-axis\n",
    "    plt.xticks(epochs)\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    plt.ylim(0, 1.05)\n",
    "    \n",
    "    # Add a horizontal line at y=1 for reference\n",
    "    plt.axhline(y=1, color='k', linestyle=':', alpha=0.3)\n",
    "    \n",
    "    # Add annotations for final values\n",
    "    final_epoch = len(epochs)\n",
    "    plt.annotate(f\"{metrics_history['val_accuracy'][-1]:.4f}\", \n",
    "                xy=(final_epoch, metrics_history['val_accuracy'][-1]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "    plt.annotate(f\"{metrics_history['val_f1'][-1]:.4f}\", \n",
    "                xy=(final_epoch, metrics_history['val_f1'][-1]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "    plt.annotate(f\"{metrics_history['val_precision'][-1]:.4f}\", \n",
    "                xy=(final_epoch, metrics_history['val_precision'][-1]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "    plt.annotate(f\"{metrics_history['val_recall'][-1]:.4f}\", \n",
    "                xy=(final_epoch, metrics_history['val_recall'][-1]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('combined_metrics.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Generate individual validation metric graphs for more detailed view\n",
    "    plot_detailed_validation_metrics(metrics_history)\n",
    "\n",
    "# New function to plot individual validation metrics for more detailed analysis\n",
    "def plot_detailed_validation_metrics(metrics_history):\n",
    "    \"\"\"Plot detailed individual validation metrics.\"\"\"\n",
    "    epochs = range(1, len(metrics_history['val_accuracy'])+1)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': metrics_history['val_accuracy'],\n",
    "        'F1 Score': metrics_history['val_f1'],\n",
    "        'Precision': metrics_history['val_precision'],\n",
    "        'Recall': metrics_history['val_recall']\n",
    "    }\n",
    "    \n",
    "    colors = ['b', 'r', 'g', 'y']\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    for i, (metric_name, metric_values) in enumerate(metrics.items(), 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        \n",
    "        # Plot the metric\n",
    "        plt.plot(epochs, metric_values, f'{colors[i-1]}-o', linewidth=2, markersize=6)\n",
    "        \n",
    "        # Add grid for better readability\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add title and labels\n",
    "        plt.title(f'Validation {metric_name} Over Epochs', fontsize=14)\n",
    "        plt.xlabel('Epochs', fontsize=12)\n",
    "        plt.ylabel(metric_name, fontsize=12)\n",
    "        \n",
    "        # Display epoch numbers on x-axis\n",
    "        plt.xticks(epochs)\n",
    "        \n",
    "        # Set y-axis limits with a bit of padding\n",
    "        min_val = max(0, min(metric_values) - 0.05)\n",
    "        max_val = min(1.05, max(metric_values) + 0.05)\n",
    "        plt.ylim(min_val, max_val)\n",
    "        \n",
    "        # Annotate each point with its value\n",
    "        for x, y in zip(epochs, metric_values):\n",
    "            plt.annotate(f\"{y:.4f}\", \n",
    "                        xy=(x, y), \n",
    "                        xytext=(0, 5), \n",
    "                        textcoords='offset points',\n",
    "                        ha='center',\n",
    "                        fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('detailed_validation_metrics.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Training function with metrics tracking\n",
    "def train_model(model, train_dataloader, val_dataloader, optimizer, num_epochs=3, label_encoder=None):\n",
    "    \"\"\"Train the BERT model and track metrics.\"\"\"\n",
    "    # Initialize metrics history\n",
    "    metrics_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'val_accuracy': [],\n",
    "        'train_f1': [],\n",
    "        'val_f1': [],\n",
    "        'train_precision': [],\n",
    "        'train_recall': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    best_val_f1 = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_steps = 0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            # Store predictions and labels for metrics calculation\n",
    "            all_train_preds.extend(preds.cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            train_steps += 1\n",
    "\n",
    "        # Calculate training metrics\n",
    "        avg_train_loss = train_loss / train_steps\n",
    "        train_metrics = calculate_metrics(all_train_preds, all_train_labels)\n",
    "\n",
    "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Training metrics: Accuracy={train_metrics['accuracy']:.4f}, F1={train_metrics['f1']:.4f}, \"\n",
    "              f\"Precision={train_metrics['precision']:.4f}, Recall={train_metrics['recall']:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        all_val_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Apply softmax to get probabilities\n",
    "                logits = outputs.logits\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                all_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "                # Get predictions\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "                # Store predictions and labels for metrics calculation\n",
    "                all_val_preds.extend(preds.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                val_steps += 1\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        avg_val_loss = val_loss / val_steps\n",
    "        val_metrics = calculate_metrics(all_val_preds, all_val_labels)\n",
    "\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Validation metrics: Accuracy={val_metrics['accuracy']:.4f}, F1={val_metrics['f1']:.4f}, \"\n",
    "              f\"Precision={val_metrics['precision']:.4f}, Recall={val_metrics['recall']:.4f}\")\n",
    "\n",
    "        # Update metrics history\n",
    "        metrics_history['train_loss'].append(avg_train_loss)\n",
    "        metrics_history['val_loss'].append(avg_val_loss)\n",
    "        metrics_history['train_accuracy'].append(train_metrics['accuracy'])\n",
    "        metrics_history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "        metrics_history['train_f1'].append(train_metrics['f1'])\n",
    "        metrics_history['val_f1'].append(val_metrics['f1'])\n",
    "        metrics_history['train_precision'].append(train_metrics['precision'])\n",
    "        metrics_history['train_recall'].append(train_metrics['recall'])\n",
    "        metrics_history['val_precision'].append(val_metrics['precision'])\n",
    "        metrics_history['val_recall'].append(val_metrics['recall'])\n",
    "\n",
    "        # Save the best model based on F1 score\n",
    "        if val_metrics['f1'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1']\n",
    "            print(f\"New best F1 score: {best_val_f1:.4f}. Saving model...\")\n",
    "            torch.save(model.state_dict(), \"best_bert_model.pt\")\n",
    "\n",
    "        # Create confusion matrix at the end of each epoch\n",
    "        if label_encoder is not None and epoch == num_epochs - 1:\n",
    "            cm = confusion_matrix(all_val_labels, all_val_preds)\n",
    "            plot_confusion_matrix(cm, label_encoder.classes_, f'Confusion Matrix - Epoch {epoch+1}')\n",
    "\n",
    "    # Plot metrics history\n",
    "    plot_metrics_history(metrics_history)\n",
    "\n",
    "    print(f\"Training complete! Best validation F1 score: {best_val_f1:.4f}\")\n",
    "    return model, metrics_history\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Parameters\n",
    "    csv_path = \"/kaggle/input/multi-agent-system-project/output_scrapy_cleaned.csv\"  # Replace with your CSV file path\n",
    "    batch_size = 16\n",
    "    learning_rate = 2e-5\n",
    "    num_epochs = 25\n",
    "    bert_model_name = \"bert-base-uncased\"  # You can use other BERT variants\n",
    "\n",
    "    # Load and preprocess data\n",
    "    df = load_dataset(csv_path)\n",
    "    df, label_encoder, num_labels = preprocess_data(df)\n",
    "\n",
    "    # Split data into train and validation sets\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Training set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = APIDataset(\n",
    "        texts=train_df['combined_text'].values,\n",
    "        labels=train_df['label'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = APIDataset(\n",
    "        texts=val_df['combined_text'].values,\n",
    "        labels=val_df['label'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        bert_model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train model\n",
    "    model, metrics_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        label_encoder=label_encoder\n",
    "    )\n",
    "\n",
    "    # Save label encoder for inference\n",
    "    import pickle\n",
    "    with open('label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "\n",
    "    print(\"Model and label encoder saved successfully!\")\n",
    "\n",
    "    # Example of how to use the model for inference with softmax probabilities\n",
    "    def predict_category_with_probs(text, model, tokenizer, label_encoder):\n",
    "        model.eval()\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].to(device)\n",
    "        attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)[0]\n",
    "\n",
    "            # Get prediction\n",
    "            prediction = torch.argmax(probs).item()\n",
    "            predicted_category = label_encoder.classes_[prediction]\n",
    "\n",
    "            # Get top 3 predictions with probabilities\n",
    "            top_probs, top_indices = torch.topk(probs, k=min(3, len(label_encoder.classes_)))\n",
    "            top_categories = [(label_encoder.classes_[idx], probs[idx].item()) for idx in top_indices]\n",
    "\n",
    "        return predicted_category, top_categories\n",
    "\n",
    "    # Test example\n",
    "    example_text = \"API that provides weather data with JSON responses\"\n",
    "    category, top_categories = predict_category_with_probs(\n",
    "        example_text, model, tokenizer, label_encoder\n",
    "    )\n",
    "\n",
    "    print(\"\\nPrediction:\")\n",
    "    print(f\"Text: {example_text}\")\n",
    "    print(f\"Predicted category: {category}\")\n",
    "    print(\"Top predictions with probabilities:\")\n",
    "    for cat, prob in top_categories:\n",
    "        print(f\"  {cat}: {prob:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7334681,
     "sourceId": 11686112,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
